{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-timw@apache.org</th>\n",
       "      <th>F71-billbarker@apache.org</th>\n",
       "      <th>F71-jfclere@apache.org</th>\n",
       "      <th>F71-rjung@apache.org</th>\n",
       "      <th>F71-pero@apache.org</th>\n",
       "      <th>F71-schultz@apache.org</th>\n",
       "      <th>F71-violetagg@apache.org</th>\n",
       "      <th>F71-markt@apache.org =  markt = Mark Emlyn David Thomas markt@apache.org@apache.org</th>\n",
       "      <th>F71-slaurent@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111475</td>\n",
       "      <td>0.190789</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>0.291197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.190789</td>\n",
       "      <td>0.047920</td>\n",
       "      <td>0.326019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075410</td>\n",
       "      <td>0.190789</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.326019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.164474</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.336365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>0.319514</td>\n",
       "      <td>0.222425</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.013756</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>0.262338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>0.319514</td>\n",
       "      <td>0.222425</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>0.308442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>0.327300</td>\n",
       "      <td>0.225463</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.070516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0.335838</td>\n",
       "      <td>0.229414</td>\n",
       "      <td>0.059016</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.054836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.347039</td>\n",
       "      <td>0.235491</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.018205</td>\n",
       "      <td>0.111650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.000000  0.000000  0.000000  0.085526  1.000000  0.000000  1.000000   \n",
       "1     1.000000  1.000000  0.111475  0.190789  0.014787  0.291197  1.000000   \n",
       "2     1.000000  1.000000  0.075410  0.190789  0.047920  0.326019  1.000000   \n",
       "3     1.000000  1.000000  0.075410  0.190789  0.049459  0.326019  1.000000   \n",
       "4     1.000000  1.000000  0.065574  0.164474  0.009903  0.336365  1.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1430  0.319514  0.222425  0.009836  0.184211  0.013756  0.121359  0.262338   \n",
       "1431  0.319514  0.222425  0.009836  0.184211  0.014000  0.121359  0.308442   \n",
       "1432  0.327300  0.225463  0.029508  0.184211  0.011586  0.070516  1.000000   \n",
       "1433  0.335838  0.229414  0.059016  0.184211  0.019918  0.054836  1.000000   \n",
       "1434  0.347039  0.235491  0.016393  0.184211  0.018205  0.111650  1.000000   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-timw@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                  0.0   \n",
       "1        0.0          0.0            0.0  ...                  0.0   \n",
       "2        0.0          0.0            0.0  ...                  0.0   \n",
       "3        0.0          0.0            0.0  ...                  0.0   \n",
       "4        0.0          0.0            0.0  ...                  0.0   \n",
       "...      ...          ...            ...  ...                  ...   \n",
       "1430     0.0          0.0            0.0  ...                  0.0   \n",
       "1431     0.0          0.0            0.0  ...                  0.0   \n",
       "1432     0.0          0.0            0.0  ...                  0.0   \n",
       "1433     0.0          0.0            0.0  ...                  0.0   \n",
       "1434     0.0          0.0            0.0  ...                  0.0   \n",
       "\n",
       "      F71-billbarker@apache.org  F71-jfclere@apache.org  F71-rjung@apache.org  \\\n",
       "0                           0.0                     0.0                   0.0   \n",
       "1                           0.0                     0.0                   0.0   \n",
       "2                           0.0                     0.0                   0.0   \n",
       "3                           0.0                     0.0                   0.0   \n",
       "4                           0.0                     0.0                   0.0   \n",
       "...                         ...                     ...                   ...   \n",
       "1430                        0.0                     0.0                   0.0   \n",
       "1431                        0.0                     0.0                   0.0   \n",
       "1432                        0.0                     0.0                   0.0   \n",
       "1433                        0.0                     0.0                   1.0   \n",
       "1434                        0.0                     0.0                   0.0   \n",
       "\n",
       "      F71-pero@apache.org  F71-schultz@apache.org  F71-violetagg@apache.org  \\\n",
       "0                     0.0                     0.0                       0.0   \n",
       "1                     0.0                     0.0                       1.0   \n",
       "2                     0.0                     0.0                       0.0   \n",
       "3                     0.0                     0.0                       0.0   \n",
       "4                     0.0                     0.0                       0.0   \n",
       "...                   ...                     ...                       ...   \n",
       "1430                  0.0                     0.0                       0.0   \n",
       "1431                  0.0                     0.0                       0.0   \n",
       "1432                  0.0                     0.0                       0.0   \n",
       "1433                  0.0                     1.0                       1.0   \n",
       "1434                  0.0                     0.0                       0.0   \n",
       "\n",
       "      F71-markt@apache.org =  markt = Mark Emlyn David Thomas markt@apache.org@apache.org  \\\n",
       "0                                                   0.0                                     \n",
       "1                                                   0.0                                     \n",
       "2                                                   0.0                                     \n",
       "3                                                   0.0                                     \n",
       "4                                                   0.0                                     \n",
       "...                                                 ...                                     \n",
       "1430                                                0.0                                     \n",
       "1431                                                0.0                                     \n",
       "1432                                                0.0                                     \n",
       "1433                                                0.0                                     \n",
       "1434                                                0.0                                     \n",
       "\n",
       "      F71-slaurent@apache.org  label  \n",
       "0                         0.0      0  \n",
       "1                         0.0      0  \n",
       "2                         0.0      0  \n",
       "3                         0.0      0  \n",
       "4                         0.0      0  \n",
       "...                       ...    ...  \n",
       "1430                      0.0      0  \n",
       "1431                      0.0      0  \n",
       "1432                      0.0      1  \n",
       "1433                      0.0      1  \n",
       "1434                      0.0      0  \n",
       "\n",
       "[1435 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/tomcat_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/tomcat_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7709923664122137\n",
      "Precision: 0.489247311827957\n",
      "Recall: 0.2791411042944785\n",
      "F1 Score: 0.35546875\n",
      "AUC Score: 0.6866653828165836\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8188757807078417\n",
      "Precision: 0.6245210727969349\n",
      "Recall: 0.5\n",
      "F1 Score: 0.555366269165247\n",
      "AUC Score: 0.7978651407191395\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.8542678695350451\n",
      "Precision: 0.7710280373831776\n",
      "Recall: 0.5061349693251533\n",
      "F1 Score: 0.6111111111111112\n",
      "AUC Score: 0.9132135684613056\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.489247</td>\n",
       "      <td>0.279141</td>\n",
       "      <td>0.355469</td>\n",
       "      <td>0.686665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.818876</td>\n",
       "      <td>0.624521</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555366</td>\n",
       "      <td>0.797865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.854268</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.506135</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.913214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.770992   0.489247  0.279141  0.355469   0.686665\n",
       "1                  SVM  0.818876   0.624521  0.500000  0.555366   0.797865\n",
       "2        Random Forest  0.854268   0.771028  0.506135  0.611111   0.913214"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('eva_tomcat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8216516308119362\n",
      "Precision: 0.6561085972850679\n",
      "Recall: 0.4447852760736196\n",
      "F1 Score: 0.5301645338208409\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.8112421929215823\n",
      "Precision: 0.6205357142857143\n",
      "Recall: 0.4263803680981595\n",
      "F1 Score: 0.5054545454545455\n",
      "AUC Score: 0.8550771685603454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='TomcatDataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
