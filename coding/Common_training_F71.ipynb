{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>F15-public</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-kinow@apache.org</th>\n",
       "      <th>F71-mcucchiara@apache.org</th>\n",
       "      <th>F71-ggregory@apache.org</th>\n",
       "      <th>F71-bayard@apache.org</th>\n",
       "      <th>F71-djones@apache.org</th>\n",
       "      <th>F71-joehni@apache.org</th>\n",
       "      <th>F71-scolebourne@apache.org</th>\n",
       "      <th>F71-mbenson@apache.org</th>\n",
       "      <th>F71-sebb@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224439</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243158</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233120</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.697933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.299830</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>0.099138</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.311221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.087749</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0    0.816014  0.830995  0.043103  1.000000  0.236316  0.000000  0.657658   \n",
       "1    0.816014  0.830995  0.043103  1.000000  0.482408  0.000000  1.000000   \n",
       "2    1.000000  1.000000  1.000000  1.000000  0.224439  0.728465  0.633205   \n",
       "3    1.000000  1.000000  1.000000  1.000000  0.243158  0.728465  0.633205   \n",
       "4    1.000000  1.000000  1.000000  1.000000  0.233120  0.728465  0.697933   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "720  0.299830  0.305064  0.099138  0.456897  0.366714  0.311221  1.000000   \n",
       "721  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "722  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "723  0.425894  0.564979  0.021552  0.051724  0.243387  0.087749  0.438345   \n",
       "724  0.425894  0.564979  0.038793  0.051724  0.191868  0.081894  0.914414   \n",
       "\n",
       "     F15-NA  F15-protected  F15-public  ...  F71-kinow@apache.org  \\\n",
       "0       0.0            0.0         0.0  ...                   0.0   \n",
       "1       0.0            0.0         1.0  ...                   0.0   \n",
       "2       0.0            0.0         0.0  ...                   0.0   \n",
       "3       0.0            0.0         1.0  ...                   0.0   \n",
       "4       0.0            0.0         1.0  ...                   0.0   \n",
       "..      ...            ...         ...  ...                   ...   \n",
       "720     0.0            0.0         0.0  ...                   0.0   \n",
       "721     0.0            0.0         0.0  ...                   0.0   \n",
       "722     0.0            0.0         0.0  ...                   0.0   \n",
       "723     0.0            0.0         0.0  ...                   0.0   \n",
       "724     0.0            0.0         0.0  ...                   0.0   \n",
       "\n",
       "     F71-mcucchiara@apache.org  F71-ggregory@apache.org  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          0.0                      1.0   \n",
       "4                          0.0                      1.0   \n",
       "..                         ...                      ...   \n",
       "720                        0.0                      1.0   \n",
       "721                        0.0                      1.0   \n",
       "722                        0.0                      1.0   \n",
       "723                        0.0                      1.0   \n",
       "724                        0.0                      1.0   \n",
       "\n",
       "     F71-bayard@apache.org  F71-djones@apache.org  F71-joehni@apache.org  \\\n",
       "0                      0.0                    0.0                    0.0   \n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      1.0                    0.0                    1.0   \n",
       "3                      1.0                    0.0                    1.0   \n",
       "4                      1.0                    0.0                    1.0   \n",
       "..                     ...                    ...                    ...   \n",
       "720                    1.0                    0.0                    0.0   \n",
       "721                    1.0                    0.0                    0.0   \n",
       "722                    1.0                    0.0                    0.0   \n",
       "723                    1.0                    0.0                    0.0   \n",
       "724                    1.0                    0.0                    0.0   \n",
       "\n",
       "     F71-scolebourne@apache.org  F71-mbenson@apache.org  F71-sebb@apache.org  \\\n",
       "0                           0.0                     1.0                  1.0   \n",
       "1                           0.0                     1.0                  1.0   \n",
       "2                           1.0                     1.0                  1.0   \n",
       "3                           1.0                     1.0                  1.0   \n",
       "4                           1.0                     1.0                  1.0   \n",
       "..                          ...                     ...                  ...   \n",
       "720                         0.0                     0.0                  1.0   \n",
       "721                         0.0                     0.0                  1.0   \n",
       "722                         0.0                     0.0                  1.0   \n",
       "723                         0.0                     0.0                  0.0   \n",
       "724                         0.0                     0.0                  1.0   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "720      1  \n",
       "721      0  \n",
       "722      0  \n",
       "723      0  \n",
       "724      0  \n",
       "\n",
       "[725 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/commons_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/commons_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-protected', 'F15-public', 'F22', 'F123', 'F77', 'F41', 'F126', 'F71-jcarman@apache.org', 'F71-pbenedict@apache.org',\n",
    "       'F71-britter@apache.org', 'F71-niallp@apache.org',\n",
    "       'F71-chas@apache.org', 'F71-oheger@apache.org',\n",
    "       'F71-brentworden@apache.org', 'F71-kinow@apache.org',\n",
    "       'F71-mcucchiara@apache.org', 'F71-ggregory@apache.org',\n",
    "       'F71-bayard@apache.org', 'F71-djones@apache.org',\n",
    "       'F71-joehni@apache.org', 'F71-scolebourne@apache.org',\n",
    "       'F71-mbenson@apache.org', 'F71-sebb@apache.org']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9274809160305344\n",
      "Precision: 0.2727272727272727\n",
      "Recall: 0.21428571428571427\n",
      "F1 Score: 0.24\n",
      "AUC Score: 0.6332885304659498\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7264631043256997\n",
      "Precision: 0.07804878048780488\n",
      "Recall: 0.38095238095238093\n",
      "F1 Score: 0.12955465587044535\n",
      "AUC Score: 0.5911098310291859\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9643765903307888\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.38095238095238093\n",
      "F1 Score: 0.5333333333333333\n",
      "AUC Score: 0.7949148745519714\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.927481</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.633289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.726463</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.129555</td>\n",
       "      <td>0.591110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.964377</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.794915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.927481   0.272727  0.214286  0.240000   0.633289\n",
       "1                  SVM  0.726463   0.078049  0.380952  0.129555   0.591110\n",
       "2        Random Forest  0.964377   0.888889  0.380952  0.533333   0.794915"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.9300254452926209\n",
      "Precision: 0.30303030303030304\n",
      "Recall: 0.23809523809523808\n",
      "F1 Score: 0.26666666666666666\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9440203562340967\n",
      "Precision: 0.45454545454545453\n",
      "Recall: 0.23809523809523808\n",
      "F1 Score: 0.3125\n",
      "AUC Score: 0.7342549923195084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
