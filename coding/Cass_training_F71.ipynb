{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-jbellis@apache.org</th>\n",
       "      <th>F71-gdusbabek@apache.org</th>\n",
       "      <th>F71-vijay2win@gmail.com</th>\n",
       "      <th>F71-dbrosius@apache.org</th>\n",
       "      <th>F71-aleksey@apache.org</th>\n",
       "      <th>F71-jake@apache.org</th>\n",
       "      <th>F71-eevans@apache.org</th>\n",
       "      <th>F71-tyler@datastax.com</th>\n",
       "      <th>F71-slebresne@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.155954</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.366623</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.135841</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.743258  0.700389  0.015686  0.040619  0.116504  0.079526  1.000000   \n",
       "1     0.743258  0.700389  0.015686  0.040619  0.218058  0.079526  0.595122   \n",
       "2     0.750369  0.704280  0.011765  0.040619  0.084618  0.064382  1.000000   \n",
       "3     0.750369  0.704280  0.011765  0.040619  0.155954  0.064382  1.000000   \n",
       "4     0.372063  0.366623  0.031373  0.040619  0.144108  0.032024  0.125831   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2579  0.001387  0.000000  0.003922  0.054159  0.135841  0.048134  1.000000   \n",
       "2580  0.249285  0.252054  0.011765  0.000000  0.130090  0.081003  0.281667   \n",
       "2581  0.249285  0.252054  0.011765  0.000000  0.121758  0.081003  0.216365   \n",
       "2582  0.249285  0.252054  0.050980  0.000000  0.085427  0.104147  1.000000   \n",
       "2583  0.249285  0.252054  0.050980  0.000000  0.141426  0.104147  0.392682   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-jbellis@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                     1.0   \n",
       "1        0.0          0.0            0.0  ...                     1.0   \n",
       "2        0.0          0.0            0.0  ...                     1.0   \n",
       "3        0.0          0.0            0.0  ...                     0.0   \n",
       "4        0.0          0.0            0.0  ...                     0.0   \n",
       "...      ...          ...            ...  ...                     ...   \n",
       "2579     0.0          0.0            0.0  ...                     0.0   \n",
       "2580     0.0          0.0            0.0  ...                     1.0   \n",
       "2581     0.0          0.0            0.0  ...                     1.0   \n",
       "2582     0.0          0.0            0.0  ...                     1.0   \n",
       "2583     0.0          0.0            0.0  ...                     1.0   \n",
       "\n",
       "      F71-gdusbabek@apache.org  F71-vijay2win@gmail.com  \\\n",
       "0                          1.0                      0.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "2579                       0.0                      0.0   \n",
       "2580                       0.0                      0.0   \n",
       "2581                       0.0                      0.0   \n",
       "2582                       0.0                      0.0   \n",
       "2583                       0.0                      0.0   \n",
       "\n",
       "      F71-dbrosius@apache.org  F71-aleksey@apache.org  F71-jake@apache.org  \\\n",
       "0                         0.0                     0.0                  0.0   \n",
       "1                         0.0                     0.0                  0.0   \n",
       "2                         0.0                     0.0                  0.0   \n",
       "3                         0.0                     0.0                  0.0   \n",
       "4                         0.0                     0.0                  0.0   \n",
       "...                       ...                     ...                  ...   \n",
       "2579                      0.0                     0.0                  0.0   \n",
       "2580                      0.0                     0.0                  0.0   \n",
       "2581                      0.0                     0.0                  0.0   \n",
       "2582                      0.0                     0.0                  0.0   \n",
       "2583                      0.0                     0.0                  0.0   \n",
       "\n",
       "      F71-eevans@apache.org  F71-tyler@datastax.com  F71-slebresne@apache.org  \\\n",
       "0                       0.0                     1.0                       0.0   \n",
       "1                       1.0                     1.0                       0.0   \n",
       "2                       1.0                     0.0                       0.0   \n",
       "3                       0.0                     0.0                       0.0   \n",
       "4                       0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "2579                    0.0                     0.0                       0.0   \n",
       "2580                    0.0                     0.0                       0.0   \n",
       "2581                    0.0                     0.0                       0.0   \n",
       "2582                    0.0                     0.0                       0.0   \n",
       "2583                    0.0                     0.0                       0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2579      0  \n",
       "2580      1  \n",
       "2581      1  \n",
       "2582      1  \n",
       "2583      1  \n",
       "\n",
       "[2584 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/cass_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/cass_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126','F71-xedin@apache.org', 'F71-jmckenzie@apache.org',\n",
    "       'F71-sylvain@datastax.com', 'F71-yukim@apache.org',\n",
    "       'F71-brandonwilliams@apache.org', 'F71-dbrosius@mebigfatguy.com',\n",
    "       'F71-johan@apache.org', 'F71-benedict@apache.org',\n",
    "       'F71-jakers@gmail.com', 'F71-marcuse@apache.org',\n",
    "       'F71-jbellis@apache.org', 'F71-gdusbabek@apache.org',\n",
    "       'F71-vijay2win@gmail.com', 'F71-dbrosius@apache.org',\n",
    "       'F71-aleksey@apache.org', 'F71-jake@apache.org',\n",
    "       'F71-eevans@apache.org', 'F71-tyler@datastax.com',\n",
    "       'F71-slebresne@apache.org']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8919646289888504\n",
      "Precision: 0.6884422110552764\n",
      "Recall: 0.3848314606741573\n",
      "F1 Score: 0.4936936936936937\n",
      "AUC Score: 0.8628275068191487\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8931180315263361\n",
      "Precision: 0.7191011235955056\n",
      "Recall: 0.3595505617977528\n",
      "F1 Score: 0.4794007490636704\n",
      "AUC Score: 0.8734628763043968\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9100346020761245\n",
      "Precision: 0.7723214285714286\n",
      "Recall: 0.4859550561797753\n",
      "F1 Score: 0.596551724137931\n",
      "AUC Score: 0.9424032181376842\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.891965</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.384831</td>\n",
       "      <td>0.493694</td>\n",
       "      <td>0.862828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.893118</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.479401</td>\n",
       "      <td>0.873463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.910035</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.596552</td>\n",
       "      <td>0.942403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.891965   0.688442  0.384831  0.493694   0.862828\n",
       "1                  SVM  0.893118   0.719101  0.359551  0.479401   0.873463\n",
       "2        Random Forest  0.910035   0.772321  0.485955  0.596552   0.942403"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.896962706651288\n",
      "Precision: 0.7619047619047619\n",
      "Recall: 0.3595505617977528\n",
      "F1 Score: 0.48854961832061067\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.895040369088812\n",
      "Precision: 0.7172774869109948\n",
      "Recall: 0.3848314606741573\n",
      "F1 Score: 0.5009140767824497\n",
      "AUC Score: 0.9307174495132754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
