{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-jbellis@apache.org</th>\n",
       "      <th>F71-gdusbabek@apache.org</th>\n",
       "      <th>F71-vijay2win@gmail.com</th>\n",
       "      <th>F71-dbrosius@apache.org</th>\n",
       "      <th>F71-aleksey@apache.org</th>\n",
       "      <th>F71-jake@apache.org</th>\n",
       "      <th>F71-eevans@apache.org</th>\n",
       "      <th>F71-tyler@datastax.com</th>\n",
       "      <th>F71-slebresne@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.155954</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.366623</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.135841</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.743258  0.700389  0.015686  0.040619  0.116504  0.079526  1.000000   \n",
       "1     0.743258  0.700389  0.015686  0.040619  0.218058  0.079526  0.595122   \n",
       "2     0.750369  0.704280  0.011765  0.040619  0.084618  0.064382  1.000000   \n",
       "3     0.750369  0.704280  0.011765  0.040619  0.155954  0.064382  1.000000   \n",
       "4     0.372063  0.366623  0.031373  0.040619  0.144108  0.032024  0.125831   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2579  0.001387  0.000000  0.003922  0.054159  0.135841  0.048134  1.000000   \n",
       "2580  0.249285  0.252054  0.011765  0.000000  0.130090  0.081003  0.281667   \n",
       "2581  0.249285  0.252054  0.011765  0.000000  0.121758  0.081003  0.216365   \n",
       "2582  0.249285  0.252054  0.050980  0.000000  0.085427  0.104147  1.000000   \n",
       "2583  0.249285  0.252054  0.050980  0.000000  0.141426  0.104147  0.392682   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-jbellis@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                     1.0   \n",
       "1        0.0          0.0            0.0  ...                     1.0   \n",
       "2        0.0          0.0            0.0  ...                     1.0   \n",
       "3        0.0          0.0            0.0  ...                     0.0   \n",
       "4        0.0          0.0            0.0  ...                     0.0   \n",
       "...      ...          ...            ...  ...                     ...   \n",
       "2579     0.0          0.0            0.0  ...                     0.0   \n",
       "2580     0.0          0.0            0.0  ...                     1.0   \n",
       "2581     0.0          0.0            0.0  ...                     1.0   \n",
       "2582     0.0          0.0            0.0  ...                     1.0   \n",
       "2583     0.0          0.0            0.0  ...                     1.0   \n",
       "\n",
       "      F71-gdusbabek@apache.org  F71-vijay2win@gmail.com  \\\n",
       "0                          1.0                      0.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "2579                       0.0                      0.0   \n",
       "2580                       0.0                      0.0   \n",
       "2581                       0.0                      0.0   \n",
       "2582                       0.0                      0.0   \n",
       "2583                       0.0                      0.0   \n",
       "\n",
       "      F71-dbrosius@apache.org  F71-aleksey@apache.org  F71-jake@apache.org  \\\n",
       "0                         0.0                     0.0                  0.0   \n",
       "1                         0.0                     0.0                  0.0   \n",
       "2                         0.0                     0.0                  0.0   \n",
       "3                         0.0                     0.0                  0.0   \n",
       "4                         0.0                     0.0                  0.0   \n",
       "...                       ...                     ...                  ...   \n",
       "2579                      0.0                     0.0                  0.0   \n",
       "2580                      0.0                     0.0                  0.0   \n",
       "2581                      0.0                     0.0                  0.0   \n",
       "2582                      0.0                     0.0                  0.0   \n",
       "2583                      0.0                     0.0                  0.0   \n",
       "\n",
       "      F71-eevans@apache.org  F71-tyler@datastax.com  F71-slebresne@apache.org  \\\n",
       "0                       0.0                     1.0                       0.0   \n",
       "1                       1.0                     1.0                       0.0   \n",
       "2                       1.0                     0.0                       0.0   \n",
       "3                       0.0                     0.0                       0.0   \n",
       "4                       0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "2579                    0.0                     0.0                       0.0   \n",
       "2580                    0.0                     0.0                       0.0   \n",
       "2581                    0.0                     0.0                       0.0   \n",
       "2582                    0.0                     0.0                       0.0   \n",
       "2583                    0.0                     0.0                       0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2579      0  \n",
       "2580      1  \n",
       "2581      1  \n",
       "2582      1  \n",
       "2583      1  \n",
       "\n",
       "[2584 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/cass_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/cass_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 1, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9058054594386774\n",
      "Precision: 0.8775510204081632\n",
      "Recall: 0.36235955056179775\n",
      "F1 Score: 0.5129224652087475\n",
      "AUC Score: 0.8440854833462625\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8992695117262591\n",
      "Precision: 0.7079646017699115\n",
      "Recall: 0.449438202247191\n",
      "F1 Score: 0.5498281786941581\n",
      "AUC Score: 0.8425877730787518\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9065743944636678\n",
      "Precision: 0.7958115183246073\n",
      "Recall: 0.42696629213483145\n",
      "F1 Score: 0.5557586837294333\n",
      "AUC Score: 0.9253428342634069\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905805</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.362360</td>\n",
       "      <td>0.512922</td>\n",
       "      <td>0.844085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.549828</td>\n",
       "      <td>0.842588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.555759</td>\n",
       "      <td>0.925343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.905805   0.877551  0.362360  0.512922   0.844085\n",
       "1                  SVM  0.899270   0.707965  0.449438  0.549828   0.842588\n",
       "2        Random Forest  0.906574   0.795812  0.426966  0.555759   0.925343"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('eva_cass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8992695117262591\n",
      "Precision: 0.7865853658536586\n",
      "Recall: 0.36235955056179775\n",
      "F1 Score: 0.49615384615384617\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9023452518262207\n",
      "Precision: 0.8\n",
      "Recall: 0.38202247191011235\n",
      "F1 Score: 0.5171102661596958\n",
      "AUC Score: 0.9234153299466981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CassDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
