{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-jbellis@apache.org</th>\n",
       "      <th>F71-gdusbabek@apache.org</th>\n",
       "      <th>F71-vijay2win@gmail.com</th>\n",
       "      <th>F71-dbrosius@apache.org</th>\n",
       "      <th>F71-aleksey@apache.org</th>\n",
       "      <th>F71-jake@apache.org</th>\n",
       "      <th>F71-eevans@apache.org</th>\n",
       "      <th>F71-tyler@datastax.com</th>\n",
       "      <th>F71-slebresne@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.155954</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.366623</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.135841</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.743258  0.700389  0.015686  0.040619  0.116504  0.079526  1.000000   \n",
       "1     0.743258  0.700389  0.015686  0.040619  0.218058  0.079526  0.595122   \n",
       "2     0.750369  0.704280  0.011765  0.040619  0.084618  0.064382  1.000000   \n",
       "3     0.750369  0.704280  0.011765  0.040619  0.155954  0.064382  1.000000   \n",
       "4     0.372063  0.366623  0.031373  0.040619  0.144108  0.032024  0.125831   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2579  0.001387  0.000000  0.003922  0.054159  0.135841  0.048134  1.000000   \n",
       "2580  0.249285  0.252054  0.011765  0.000000  0.130090  0.081003  0.281667   \n",
       "2581  0.249285  0.252054  0.011765  0.000000  0.121758  0.081003  0.216365   \n",
       "2582  0.249285  0.252054  0.050980  0.000000  0.085427  0.104147  1.000000   \n",
       "2583  0.249285  0.252054  0.050980  0.000000  0.141426  0.104147  0.392682   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-jbellis@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                     1.0   \n",
       "1        0.0          0.0            0.0  ...                     1.0   \n",
       "2        0.0          0.0            0.0  ...                     1.0   \n",
       "3        0.0          0.0            0.0  ...                     0.0   \n",
       "4        0.0          0.0            0.0  ...                     0.0   \n",
       "...      ...          ...            ...  ...                     ...   \n",
       "2579     0.0          0.0            0.0  ...                     0.0   \n",
       "2580     0.0          0.0            0.0  ...                     1.0   \n",
       "2581     0.0          0.0            0.0  ...                     1.0   \n",
       "2582     0.0          0.0            0.0  ...                     1.0   \n",
       "2583     0.0          0.0            0.0  ...                     1.0   \n",
       "\n",
       "      F71-gdusbabek@apache.org  F71-vijay2win@gmail.com  \\\n",
       "0                          1.0                      0.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "2579                       0.0                      0.0   \n",
       "2580                       0.0                      0.0   \n",
       "2581                       0.0                      0.0   \n",
       "2582                       0.0                      0.0   \n",
       "2583                       0.0                      0.0   \n",
       "\n",
       "      F71-dbrosius@apache.org  F71-aleksey@apache.org  F71-jake@apache.org  \\\n",
       "0                         0.0                     0.0                  0.0   \n",
       "1                         0.0                     0.0                  0.0   \n",
       "2                         0.0                     0.0                  0.0   \n",
       "3                         0.0                     0.0                  0.0   \n",
       "4                         0.0                     0.0                  0.0   \n",
       "...                       ...                     ...                  ...   \n",
       "2579                      0.0                     0.0                  0.0   \n",
       "2580                      0.0                     0.0                  0.0   \n",
       "2581                      0.0                     0.0                  0.0   \n",
       "2582                      0.0                     0.0                  0.0   \n",
       "2583                      0.0                     0.0                  0.0   \n",
       "\n",
       "      F71-eevans@apache.org  F71-tyler@datastax.com  F71-slebresne@apache.org  \\\n",
       "0                       0.0                     1.0                       0.0   \n",
       "1                       1.0                     1.0                       0.0   \n",
       "2                       1.0                     0.0                       0.0   \n",
       "3                       0.0                     0.0                       0.0   \n",
       "4                       0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "2579                    0.0                     0.0                       0.0   \n",
       "2580                    0.0                     0.0                       0.0   \n",
       "2581                    0.0                     0.0                       0.0   \n",
       "2582                    0.0                     0.0                       0.0   \n",
       "2583                    0.0                     0.0                       0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2579      0  \n",
       "2580      1  \n",
       "2581      1  \n",
       "2582      1  \n",
       "2583      1  \n",
       "\n",
       "[2584 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/cass_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/cass_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 1, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9058054594386774\n",
      "Precision: 0.8775510204081632\n",
      "Recall: 0.36235955056179775\n",
      "F1 Score: 0.5129224652087475\n",
      "AUC Score: 0.8440854833462625\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8992695117262591\n",
      "Precision: 0.7079646017699115\n",
      "Recall: 0.449438202247191\n",
      "F1 Score: 0.5498281786941581\n",
      "AUC Score: 0.8424864242636572\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9061899269511726\n",
      "Precision: 0.8043478260869565\n",
      "Recall: 0.4157303370786517\n",
      "F1 Score: 0.5481481481481482\n",
      "AUC Score: 0.9267980030529765\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905805</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.362360</td>\n",
       "      <td>0.512922</td>\n",
       "      <td>0.844085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.549828</td>\n",
       "      <td>0.842486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.548148</td>\n",
       "      <td>0.926798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.905805   0.877551  0.362360  0.512922   0.844085\n",
       "1                  SVM  0.899270   0.707965  0.449438  0.549828   0.842486\n",
       "2        Random Forest  0.906190   0.804348  0.415730  0.548148   0.926798"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8992695117262591\n",
      "Precision: 0.7865853658536586\n",
      "Recall: 0.36235955056179775\n",
      "F1 Score: 0.49615384615384617\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9015763168012303\n",
      "Precision: 0.7976190476190477\n",
      "Recall: 0.37640449438202245\n",
      "F1 Score: 0.5114503816793893\n",
      "AUC Score: 0.9247053377042617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train_data['label'].value_counts(normalize=\"True\")\n",
    "\n",
    "length = len(train_data)\n",
    "\n",
    "AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: 0.8517801857585139\n",
      "Number of ones: 0.14821981424148606\n"
     ]
    }
   ],
   "source": [
    "number_zeros = label_counts.get(0,0)\n",
    "number_ones = label_counts.get(1,0)\n",
    "\n",
    "print(f\"Number of zeros: {number_zeros}\")\n",
    "print(f\"Number of ones: {number_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='metrics_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'num_zeros': label_counts.get(0, 0),\n",
    "        'num_ones': label_counts.get(1, 0),\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CassDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
