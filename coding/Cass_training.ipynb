{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-jbellis@apache.org</th>\n",
       "      <th>F71-gdusbabek@apache.org</th>\n",
       "      <th>F71-vijay2win@gmail.com</th>\n",
       "      <th>F71-dbrosius@apache.org</th>\n",
       "      <th>F71-aleksey@apache.org</th>\n",
       "      <th>F71-jake@apache.org</th>\n",
       "      <th>F71-eevans@apache.org</th>\n",
       "      <th>F71-tyler@datastax.com</th>\n",
       "      <th>F71-slebresne@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.155954</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.366623</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.135841</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.743258  0.700389  0.015686  0.040619  0.116504  0.079526  1.000000   \n",
       "1     0.743258  0.700389  0.015686  0.040619  0.218058  0.079526  0.595122   \n",
       "2     0.750369  0.704280  0.011765  0.040619  0.084618  0.064382  1.000000   \n",
       "3     0.750369  0.704280  0.011765  0.040619  0.155954  0.064382  1.000000   \n",
       "4     0.372063  0.366623  0.031373  0.040619  0.144108  0.032024  0.125831   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2579  0.001387  0.000000  0.003922  0.054159  0.135841  0.048134  1.000000   \n",
       "2580  0.249285  0.252054  0.011765  0.000000  0.130090  0.081003  0.281667   \n",
       "2581  0.249285  0.252054  0.011765  0.000000  0.121758  0.081003  0.216365   \n",
       "2582  0.249285  0.252054  0.050980  0.000000  0.085427  0.104147  1.000000   \n",
       "2583  0.249285  0.252054  0.050980  0.000000  0.141426  0.104147  0.392682   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-jbellis@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                     1.0   \n",
       "1        0.0          0.0            0.0  ...                     1.0   \n",
       "2        0.0          0.0            0.0  ...                     1.0   \n",
       "3        0.0          0.0            0.0  ...                     0.0   \n",
       "4        0.0          0.0            0.0  ...                     0.0   \n",
       "...      ...          ...            ...  ...                     ...   \n",
       "2579     0.0          0.0            0.0  ...                     0.0   \n",
       "2580     0.0          0.0            0.0  ...                     1.0   \n",
       "2581     0.0          0.0            0.0  ...                     1.0   \n",
       "2582     0.0          0.0            0.0  ...                     1.0   \n",
       "2583     0.0          0.0            0.0  ...                     1.0   \n",
       "\n",
       "      F71-gdusbabek@apache.org  F71-vijay2win@gmail.com  \\\n",
       "0                          1.0                      0.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "2579                       0.0                      0.0   \n",
       "2580                       0.0                      0.0   \n",
       "2581                       0.0                      0.0   \n",
       "2582                       0.0                      0.0   \n",
       "2583                       0.0                      0.0   \n",
       "\n",
       "      F71-dbrosius@apache.org  F71-aleksey@apache.org  F71-jake@apache.org  \\\n",
       "0                         0.0                     0.0                  0.0   \n",
       "1                         0.0                     0.0                  0.0   \n",
       "2                         0.0                     0.0                  0.0   \n",
       "3                         0.0                     0.0                  0.0   \n",
       "4                         0.0                     0.0                  0.0   \n",
       "...                       ...                     ...                  ...   \n",
       "2579                      0.0                     0.0                  0.0   \n",
       "2580                      0.0                     0.0                  0.0   \n",
       "2581                      0.0                     0.0                  0.0   \n",
       "2582                      0.0                     0.0                  0.0   \n",
       "2583                      0.0                     0.0                  0.0   \n",
       "\n",
       "      F71-eevans@apache.org  F71-tyler@datastax.com  F71-slebresne@apache.org  \\\n",
       "0                       0.0                     1.0                       0.0   \n",
       "1                       1.0                     1.0                       0.0   \n",
       "2                       1.0                     0.0                       0.0   \n",
       "3                       0.0                     0.0                       0.0   \n",
       "4                       0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "2579                    0.0                     0.0                       0.0   \n",
       "2580                    0.0                     0.0                       0.0   \n",
       "2581                    0.0                     0.0                       0.0   \n",
       "2582                    0.0                     0.0                       0.0   \n",
       "2583                    0.0                     0.0                       0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2579      0  \n",
       "2580      1  \n",
       "2581      1  \n",
       "2582      1  \n",
       "2583      1  \n",
       "\n",
       "[2584 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/cass_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/cass_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 1, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9058054594386774\n",
      "Precision: 0.8775510204081632\n",
      "Recall: 0.36235955056179775\n",
      "F1 Score: 0.5129224652087475\n",
      "AUC Score: 0.8440854833462625\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8992695117262591\n",
      "Precision: 0.7079646017699115\n",
      "Recall: 0.449438202247191\n",
      "F1 Score: 0.5498281786941581\n",
      "AUC Score: 0.842582768198994\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9042675893886967\n",
      "Precision: 0.7891891891891892\n",
      "Recall: 0.4101123595505618\n",
      "F1 Score: 0.5397412199630314\n",
      "AUC Score: 0.9236780861339806\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905805</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.362360</td>\n",
       "      <td>0.512922</td>\n",
       "      <td>0.844085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.549828</td>\n",
       "      <td>0.842583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.904268</td>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.410112</td>\n",
       "      <td>0.539741</td>\n",
       "      <td>0.923678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.905805   0.877551  0.362360  0.512922   0.844085\n",
       "1                  SVM  0.899270   0.707965  0.449438  0.549828   0.842583\n",
       "2        Random Forest  0.904268   0.789189  0.410112  0.539741   0.923678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.9000384467512496\n",
      "Precision: 0.8\n",
      "Recall: 0.3595505617977528\n",
      "F1 Score: 0.49612403100775193\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9015763168012303\n",
      "Precision: 0.7941176470588235\n",
      "Recall: 0.3792134831460674\n",
      "F1 Score: 0.5133079847908745\n",
      "AUC Score: 0.9234278421460925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CassDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
