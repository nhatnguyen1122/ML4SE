{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-markrmiller@apache.org</th>\n",
       "      <th>F71-noble@apache.org</th>\n",
       "      <th>F71-yonik@apache.org</th>\n",
       "      <th>F71-mikemccand@apache.org</th>\n",
       "      <th>F71-shaie@apache.org</th>\n",
       "      <th>F71-rjernst@apache.org</th>\n",
       "      <th>F71-romseygeek@apache.org</th>\n",
       "      <th>F71-erick@apache.org</th>\n",
       "      <th>F71-uschindler@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.023909</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.314867</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.023909</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.064721</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747947</td>\n",
       "      <td>0.511462</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.448043</td>\n",
       "      <td>0.105411</td>\n",
       "      <td>0.565774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.747947</td>\n",
       "      <td>0.511462</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.448043</td>\n",
       "      <td>0.105411</td>\n",
       "      <td>0.565774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326937</td>\n",
       "      <td>0.225290</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.486329</td>\n",
       "      <td>0.053511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.626310</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.528170</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>0.621172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.615383</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.623578</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>0.812837</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.325926</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.039898</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3259 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.035424  0.023909  0.325926  0.111765  0.314867  0.029159  1.000000   \n",
       "1     0.035424  0.023909  0.325926  0.111765  0.064721  0.029159  1.000000   \n",
       "2     0.747947  0.511462  0.170370  0.505882  0.448043  0.105411  0.565774   \n",
       "3     0.747947  0.511462  0.170370  0.505882  0.448043  0.105411  0.565774   \n",
       "4     0.326937  0.225290  0.014815  0.111765  0.486329  0.053511  1.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3254  0.812837  0.594281  0.325926  0.045098  0.626310  0.046278  1.000000   \n",
       "3255  0.812837  0.594281  0.325926  0.045098  0.528170  0.046278  0.621172   \n",
       "3256  0.812837  0.594281  0.325926  0.045098  0.615383  0.046278  1.000000   \n",
       "3257  0.812837  0.594281  0.325926  0.045098  0.623578  0.046278  1.000000   \n",
       "3258  0.812837  0.594281  0.325926  0.045098  0.039898  0.046278  0.691667   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-markrmiller@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                         0.0   \n",
       "1        0.0          0.0            0.0  ...                         0.0   \n",
       "2        0.0          0.0            0.0  ...                         1.0   \n",
       "3        0.0          0.0            0.0  ...                         1.0   \n",
       "4        0.0          0.0            0.0  ...                         0.0   \n",
       "...      ...          ...            ...  ...                         ...   \n",
       "3254     0.0          0.0            0.0  ...                         0.0   \n",
       "3255     0.0          0.0            0.0  ...                         0.0   \n",
       "3256     0.0          0.0            0.0  ...                         0.0   \n",
       "3257     0.0          0.0            0.0  ...                         0.0   \n",
       "3258     0.0          1.0            0.0  ...                         0.0   \n",
       "\n",
       "      F71-noble@apache.org  F71-yonik@apache.org  F71-mikemccand@apache.org  \\\n",
       "0                      0.0                   0.0                        1.0   \n",
       "1                      0.0                   0.0                        1.0   \n",
       "2                      0.0                   0.0                        1.0   \n",
       "3                      0.0                   0.0                        1.0   \n",
       "4                      0.0                   0.0                        1.0   \n",
       "...                    ...                   ...                        ...   \n",
       "3254                   0.0                   0.0                        0.0   \n",
       "3255                   0.0                   0.0                        1.0   \n",
       "3256                   0.0                   0.0                        1.0   \n",
       "3257                   0.0                   0.0                        1.0   \n",
       "3258                   0.0                   0.0                        1.0   \n",
       "\n",
       "      F71-shaie@apache.org  F71-rjernst@apache.org  F71-romseygeek@apache.org  \\\n",
       "0                      1.0                     1.0                        0.0   \n",
       "1                      1.0                     1.0                        0.0   \n",
       "2                      1.0                     0.0                        0.0   \n",
       "3                      1.0                     0.0                        0.0   \n",
       "4                      1.0                     0.0                        0.0   \n",
       "...                    ...                     ...                        ...   \n",
       "3254                   1.0                     0.0                        0.0   \n",
       "3255                   1.0                     0.0                        0.0   \n",
       "3256                   1.0                     0.0                        0.0   \n",
       "3257                   1.0                     0.0                        0.0   \n",
       "3258                   1.0                     0.0                        0.0   \n",
       "\n",
       "      F71-erick@apache.org  F71-uschindler@apache.org  label  \n",
       "0                      0.0                        1.0      0  \n",
       "1                      0.0                        1.0      0  \n",
       "2                      0.0                        1.0      1  \n",
       "3                      0.0                        1.0      1  \n",
       "4                      0.0                        0.0      1  \n",
       "...                    ...                        ...    ...  \n",
       "3254                   0.0                        0.0      0  \n",
       "3255                   0.0                        0.0      1  \n",
       "3256                   0.0                        0.0      1  \n",
       "3257                   0.0                        0.0      1  \n",
       "3258                   0.0                        0.0      1  \n",
       "\n",
       "[3259 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/lucence_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/lucence_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.6957664233576643\n",
      "Precision: 0.5846774193548387\n",
      "Recall: 0.3724315068493151\n",
      "F1 Score: 0.45502092050209203\n",
      "AUC Score: 0.6417746766528487\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.785985401459854\n",
      "Precision: 0.7959183673469388\n",
      "Recall: 0.5008561643835616\n",
      "F1 Score: 0.6148187073042565\n",
      "AUC Score: 0.8023280691425763\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.8645255474452554\n",
      "Precision: 0.9093023255813953\n",
      "Recall: 0.6695205479452054\n",
      "F1 Score: 0.7712031558185405\n",
      "AUC Score: 0.9334037256996499\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.695766</td>\n",
       "      <td>0.584677</td>\n",
       "      <td>0.372432</td>\n",
       "      <td>0.455021</td>\n",
       "      <td>0.641775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.785985</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.500856</td>\n",
       "      <td>0.614819</td>\n",
       "      <td>0.802328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.864526</td>\n",
       "      <td>0.909302</td>\n",
       "      <td>0.669521</td>\n",
       "      <td>0.771203</td>\n",
       "      <td>0.933404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.695766   0.584677  0.372432  0.455021   0.641775\n",
       "1                  SVM  0.785985   0.795918  0.500856  0.614819   0.802328\n",
       "2        Random Forest  0.864526   0.909302  0.669521  0.771203   0.933404"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8026277372262773\n",
      "Precision: 0.8628318584070797\n",
      "Recall: 0.5008561643835616\n",
      "F1 Score: 0.6338028169014085\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.8189781021897811\n",
      "Precision: 0.8605263157894737\n",
      "Recall: 0.559931506849315\n",
      "F1 Score: 0.6784232365145229\n",
      "AUC Score: 0.8555965155589005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train_data['label'].value_counts(normalize=\"True\")\n",
    "\n",
    "length = len(train_data)\n",
    "\n",
    "AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='metrics_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'num_zeros': label_counts.get(0, 0),\n",
    "        'num_ones': label_counts.get(1, 0),\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='Antdataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
