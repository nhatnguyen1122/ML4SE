{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>F15-public</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-kinow@apache.org</th>\n",
       "      <th>F71-mcucchiara@apache.org</th>\n",
       "      <th>F71-ggregory@apache.org</th>\n",
       "      <th>F71-bayard@apache.org</th>\n",
       "      <th>F71-djones@apache.org</th>\n",
       "      <th>F71-joehni@apache.org</th>\n",
       "      <th>F71-scolebourne@apache.org</th>\n",
       "      <th>F71-mbenson@apache.org</th>\n",
       "      <th>F71-sebb@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224439</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243158</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233120</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.697933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.299830</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>0.099138</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.311221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.087749</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0    0.816014  0.830995  0.043103  1.000000  0.236316  0.000000  0.657658   \n",
       "1    0.816014  0.830995  0.043103  1.000000  0.482408  0.000000  1.000000   \n",
       "2    1.000000  1.000000  1.000000  1.000000  0.224439  0.728465  0.633205   \n",
       "3    1.000000  1.000000  1.000000  1.000000  0.243158  0.728465  0.633205   \n",
       "4    1.000000  1.000000  1.000000  1.000000  0.233120  0.728465  0.697933   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "720  0.299830  0.305064  0.099138  0.456897  0.366714  0.311221  1.000000   \n",
       "721  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "722  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "723  0.425894  0.564979  0.021552  0.051724  0.243387  0.087749  0.438345   \n",
       "724  0.425894  0.564979  0.038793  0.051724  0.191868  0.081894  0.914414   \n",
       "\n",
       "     F15-NA  F15-protected  F15-public  ...  F71-kinow@apache.org  \\\n",
       "0       0.0            0.0         0.0  ...                   0.0   \n",
       "1       0.0            0.0         1.0  ...                   0.0   \n",
       "2       0.0            0.0         0.0  ...                   0.0   \n",
       "3       0.0            0.0         1.0  ...                   0.0   \n",
       "4       0.0            0.0         1.0  ...                   0.0   \n",
       "..      ...            ...         ...  ...                   ...   \n",
       "720     0.0            0.0         0.0  ...                   0.0   \n",
       "721     0.0            0.0         0.0  ...                   0.0   \n",
       "722     0.0            0.0         0.0  ...                   0.0   \n",
       "723     0.0            0.0         0.0  ...                   0.0   \n",
       "724     0.0            0.0         0.0  ...                   0.0   \n",
       "\n",
       "     F71-mcucchiara@apache.org  F71-ggregory@apache.org  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          0.0                      1.0   \n",
       "4                          0.0                      1.0   \n",
       "..                         ...                      ...   \n",
       "720                        0.0                      1.0   \n",
       "721                        0.0                      1.0   \n",
       "722                        0.0                      1.0   \n",
       "723                        0.0                      1.0   \n",
       "724                        0.0                      1.0   \n",
       "\n",
       "     F71-bayard@apache.org  F71-djones@apache.org  F71-joehni@apache.org  \\\n",
       "0                      0.0                    0.0                    0.0   \n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      1.0                    0.0                    1.0   \n",
       "3                      1.0                    0.0                    1.0   \n",
       "4                      1.0                    0.0                    1.0   \n",
       "..                     ...                    ...                    ...   \n",
       "720                    1.0                    0.0                    0.0   \n",
       "721                    1.0                    0.0                    0.0   \n",
       "722                    1.0                    0.0                    0.0   \n",
       "723                    1.0                    0.0                    0.0   \n",
       "724                    1.0                    0.0                    0.0   \n",
       "\n",
       "     F71-scolebourne@apache.org  F71-mbenson@apache.org  F71-sebb@apache.org  \\\n",
       "0                           0.0                     1.0                  1.0   \n",
       "1                           0.0                     1.0                  1.0   \n",
       "2                           1.0                     1.0                  1.0   \n",
       "3                           1.0                     1.0                  1.0   \n",
       "4                           1.0                     1.0                  1.0   \n",
       "..                          ...                     ...                  ...   \n",
       "720                         0.0                     0.0                  1.0   \n",
       "721                         0.0                     0.0                  1.0   \n",
       "722                         0.0                     0.0                  1.0   \n",
       "723                         0.0                     0.0                  0.0   \n",
       "724                         0.0                     0.0                  1.0   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "720      1  \n",
       "721      0  \n",
       "722      0  \n",
       "723      0  \n",
       "724      0  \n",
       "\n",
       "[725 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/commons_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/commons_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-protected', 'F15-public', 'F22', 'F123', 'F77', 'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.94529262086514\n",
      "Precision: 0.4666666666666667\n",
      "Recall: 0.16666666666666666\n",
      "F1 Score: 0.24561403508771928\n",
      "AUC Score: 0.6025985663082436\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.9096692111959288\n",
      "Precision: 0.24561403508771928\n",
      "Recall: 0.3333333333333333\n",
      "F1 Score: 0.2828282828282828\n",
      "AUC Score: 0.6116551459293396\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9656488549618321\n",
      "Precision: 0.9411764705882353\n",
      "Recall: 0.38095238095238093\n",
      "F1 Score: 0.5423728813559322\n",
      "AUC Score: 0.7214381720430106\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.945293</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.602599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.611655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.965649</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.721438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.945293   0.466667  0.166667  0.245614   0.602599\n",
       "1                  SVM  0.909669   0.245614  0.333333  0.282828   0.611655\n",
       "2        Random Forest  0.965649   0.941176  0.380952  0.542373   0.721438"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.955470737913486\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.2619047619047619\n",
      "F1 Score: 0.38596491228070173\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9541984732824428\n",
      "Precision: 0.6875\n",
      "Recall: 0.2619047619047619\n",
      "F1 Score: 0.3793103448275862\n",
      "AUC Score: 0.6666986687147977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CommonsDataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
