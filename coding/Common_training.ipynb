{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>F15-public</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-kinow@apache.org</th>\n",
       "      <th>F71-mcucchiara@apache.org</th>\n",
       "      <th>F71-ggregory@apache.org</th>\n",
       "      <th>F71-bayard@apache.org</th>\n",
       "      <th>F71-djones@apache.org</th>\n",
       "      <th>F71-joehni@apache.org</th>\n",
       "      <th>F71-scolebourne@apache.org</th>\n",
       "      <th>F71-mbenson@apache.org</th>\n",
       "      <th>F71-sebb@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816014</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224439</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243158</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233120</td>\n",
       "      <td>0.728465</td>\n",
       "      <td>0.697933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.299830</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>0.099138</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.366714</td>\n",
       "      <td>0.311221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.628620</td>\n",
       "      <td>0.697376</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.243387</td>\n",
       "      <td>0.087749</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.425894</td>\n",
       "      <td>0.564979</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>0.081894</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0    0.816014  0.830995  0.043103  1.000000  0.236316  0.000000  0.657658   \n",
       "1    0.816014  0.830995  0.043103  1.000000  0.482408  0.000000  1.000000   \n",
       "2    1.000000  1.000000  1.000000  1.000000  0.224439  0.728465  0.633205   \n",
       "3    1.000000  1.000000  1.000000  1.000000  0.243158  0.728465  0.633205   \n",
       "4    1.000000  1.000000  1.000000  1.000000  0.233120  0.728465  0.697933   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "720  0.299830  0.305064  0.099138  0.456897  0.366714  0.311221  1.000000   \n",
       "721  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "722  0.628620  0.697376  0.030172  0.456897  0.499639  0.549429  1.000000   \n",
       "723  0.425894  0.564979  0.021552  0.051724  0.243387  0.087749  0.438345   \n",
       "724  0.425894  0.564979  0.038793  0.051724  0.191868  0.081894  0.914414   \n",
       "\n",
       "     F15-NA  F15-protected  F15-public  ...  F71-kinow@apache.org  \\\n",
       "0       0.0            0.0         0.0  ...                   0.0   \n",
       "1       0.0            0.0         1.0  ...                   0.0   \n",
       "2       0.0            0.0         0.0  ...                   0.0   \n",
       "3       0.0            0.0         1.0  ...                   0.0   \n",
       "4       0.0            0.0         1.0  ...                   0.0   \n",
       "..      ...            ...         ...  ...                   ...   \n",
       "720     0.0            0.0         0.0  ...                   0.0   \n",
       "721     0.0            0.0         0.0  ...                   0.0   \n",
       "722     0.0            0.0         0.0  ...                   0.0   \n",
       "723     0.0            0.0         0.0  ...                   0.0   \n",
       "724     0.0            0.0         0.0  ...                   0.0   \n",
       "\n",
       "     F71-mcucchiara@apache.org  F71-ggregory@apache.org  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      1.0   \n",
       "3                          0.0                      1.0   \n",
       "4                          0.0                      1.0   \n",
       "..                         ...                      ...   \n",
       "720                        0.0                      1.0   \n",
       "721                        0.0                      1.0   \n",
       "722                        0.0                      1.0   \n",
       "723                        0.0                      1.0   \n",
       "724                        0.0                      1.0   \n",
       "\n",
       "     F71-bayard@apache.org  F71-djones@apache.org  F71-joehni@apache.org  \\\n",
       "0                      0.0                    0.0                    0.0   \n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      1.0                    0.0                    1.0   \n",
       "3                      1.0                    0.0                    1.0   \n",
       "4                      1.0                    0.0                    1.0   \n",
       "..                     ...                    ...                    ...   \n",
       "720                    1.0                    0.0                    0.0   \n",
       "721                    1.0                    0.0                    0.0   \n",
       "722                    1.0                    0.0                    0.0   \n",
       "723                    1.0                    0.0                    0.0   \n",
       "724                    1.0                    0.0                    0.0   \n",
       "\n",
       "     F71-scolebourne@apache.org  F71-mbenson@apache.org  F71-sebb@apache.org  \\\n",
       "0                           0.0                     1.0                  1.0   \n",
       "1                           0.0                     1.0                  1.0   \n",
       "2                           1.0                     1.0                  1.0   \n",
       "3                           1.0                     1.0                  1.0   \n",
       "4                           1.0                     1.0                  1.0   \n",
       "..                          ...                     ...                  ...   \n",
       "720                         0.0                     0.0                  1.0   \n",
       "721                         0.0                     0.0                  1.0   \n",
       "722                         0.0                     0.0                  1.0   \n",
       "723                         0.0                     0.0                  0.0   \n",
       "724                         0.0                     0.0                  1.0   \n",
       "\n",
       "     label  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "720      1  \n",
       "721      0  \n",
       "722      0  \n",
       "723      0  \n",
       "724      0  \n",
       "\n",
       "[725 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/commons_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/commons_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-protected', 'F15-public', 'F22', 'F123', 'F77', 'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.94529262086514\n",
      "Precision: 0.4666666666666667\n",
      "Recall: 0.16666666666666666\n",
      "F1 Score: 0.24561403508771928\n",
      "AUC Score: 0.6025985663082436\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.9096692111959288\n",
      "Precision: 0.24561403508771928\n",
      "Recall: 0.3333333333333333\n",
      "F1 Score: 0.2828282828282828\n",
      "AUC Score: 0.6124231950844854\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9631043256997456\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.35714285714285715\n",
      "F1 Score: 0.5084745762711864\n",
      "AUC Score: 0.7263184843830005\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.945293</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.602599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.612423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.963104</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.726318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.945293   0.466667  0.166667  0.245614   0.602599\n",
       "1                  SVM  0.909669   0.245614  0.333333  0.282828   0.612423\n",
       "2        Random Forest  0.963104   0.882353  0.357143  0.508475   0.726318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.955470737913486\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.2619047619047619\n",
      "F1 Score: 0.38596491228070173\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9541984732824428\n",
      "Precision: 0.6875\n",
      "Recall: 0.2619047619047619\n",
      "F1 Score: 0.3793103448275862\n",
      "AUC Score: 0.689452124935996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CommonsDataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
