{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-jbellis@apache.org</th>\n",
       "      <th>F71-gdusbabek@apache.org</th>\n",
       "      <th>F71-vijay2win@gmail.com</th>\n",
       "      <th>F71-dbrosius@apache.org</th>\n",
       "      <th>F71-aleksey@apache.org</th>\n",
       "      <th>F71-jake@apache.org</th>\n",
       "      <th>F71-eevans@apache.org</th>\n",
       "      <th>F71-tyler@datastax.com</th>\n",
       "      <th>F71-slebresne@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.116504</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743258</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.218058</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>0.595122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750369</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.155954</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.366623</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.144108</td>\n",
       "      <td>0.032024</td>\n",
       "      <td>0.125831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.135841</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130090</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121758</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141426</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.392682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2584 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0     0.743258  0.700389  0.015686  0.040619  0.116504  0.079526  1.000000   \n",
       "1     0.743258  0.700389  0.015686  0.040619  0.218058  0.079526  0.595122   \n",
       "2     0.750369  0.704280  0.011765  0.040619  0.084618  0.064382  1.000000   \n",
       "3     0.750369  0.704280  0.011765  0.040619  0.155954  0.064382  1.000000   \n",
       "4     0.372063  0.366623  0.031373  0.040619  0.144108  0.032024  0.125831   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2579  0.001387  0.000000  0.003922  0.054159  0.135841  0.048134  1.000000   \n",
       "2580  0.249285  0.252054  0.011765  0.000000  0.130090  0.081003  0.281667   \n",
       "2581  0.249285  0.252054  0.011765  0.000000  0.121758  0.081003  0.216365   \n",
       "2582  0.249285  0.252054  0.050980  0.000000  0.085427  0.104147  1.000000   \n",
       "2583  0.249285  0.252054  0.050980  0.000000  0.141426  0.104147  0.392682   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-jbellis@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                     1.0   \n",
       "1        0.0          0.0            0.0  ...                     1.0   \n",
       "2        0.0          0.0            0.0  ...                     1.0   \n",
       "3        0.0          0.0            0.0  ...                     0.0   \n",
       "4        0.0          0.0            0.0  ...                     0.0   \n",
       "...      ...          ...            ...  ...                     ...   \n",
       "2579     0.0          0.0            0.0  ...                     0.0   \n",
       "2580     0.0          0.0            0.0  ...                     1.0   \n",
       "2581     0.0          0.0            0.0  ...                     1.0   \n",
       "2582     0.0          0.0            0.0  ...                     1.0   \n",
       "2583     0.0          0.0            0.0  ...                     1.0   \n",
       "\n",
       "      F71-gdusbabek@apache.org  F71-vijay2win@gmail.com  \\\n",
       "0                          1.0                      0.0   \n",
       "1                          1.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "2579                       0.0                      0.0   \n",
       "2580                       0.0                      0.0   \n",
       "2581                       0.0                      0.0   \n",
       "2582                       0.0                      0.0   \n",
       "2583                       0.0                      0.0   \n",
       "\n",
       "      F71-dbrosius@apache.org  F71-aleksey@apache.org  F71-jake@apache.org  \\\n",
       "0                         0.0                     0.0                  0.0   \n",
       "1                         0.0                     0.0                  0.0   \n",
       "2                         0.0                     0.0                  0.0   \n",
       "3                         0.0                     0.0                  0.0   \n",
       "4                         0.0                     0.0                  0.0   \n",
       "...                       ...                     ...                  ...   \n",
       "2579                      0.0                     0.0                  0.0   \n",
       "2580                      0.0                     0.0                  0.0   \n",
       "2581                      0.0                     0.0                  0.0   \n",
       "2582                      0.0                     0.0                  0.0   \n",
       "2583                      0.0                     0.0                  0.0   \n",
       "\n",
       "      F71-eevans@apache.org  F71-tyler@datastax.com  F71-slebresne@apache.org  \\\n",
       "0                       0.0                     1.0                       0.0   \n",
       "1                       1.0                     1.0                       0.0   \n",
       "2                       1.0                     0.0                       0.0   \n",
       "3                       0.0                     0.0                       0.0   \n",
       "4                       0.0                     0.0                       0.0   \n",
       "...                     ...                     ...                       ...   \n",
       "2579                    0.0                     0.0                       0.0   \n",
       "2580                    0.0                     0.0                       0.0   \n",
       "2581                    0.0                     0.0                       0.0   \n",
       "2582                    0.0                     0.0                       0.0   \n",
       "2583                    0.0                     0.0                       0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "2579      0  \n",
       "2580      1  \n",
       "2581      1  \n",
       "2582      1  \n",
       "2583      1  \n",
       "\n",
       "[2584 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/cass_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/cass_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F15-public', 'F68', 'F123', 'F22', 'F15-private', 'F104', 'F41', 'F15-protected', 'F25']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8623606305267205\n",
      "Precision: 0.4772727272727273\n",
      "Recall: 0.05898876404494382\n",
      "F1 Score: 0.105\n",
      "AUC Score: 0.7027470533770426\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8896578239138793\n",
      "Precision: 0.8876404494382022\n",
      "Recall: 0.22191011235955055\n",
      "F1 Score: 0.3550561797752809\n",
      "AUC Score: 0.7402436125222092\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9177239523260284\n",
      "Precision: 0.9863013698630136\n",
      "Recall: 0.4044943820224719\n",
      "F1 Score: 0.5737051792828686\n",
      "AUC Score: 0.9141075048171967\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.862361</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.058989</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.702747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.889658</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.221910</td>\n",
       "      <td>0.355056</td>\n",
       "      <td>0.740244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.917724</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>0.573705</td>\n",
       "      <td>0.914108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.862361   0.477273  0.058989  0.105000   0.702747\n",
       "1                  SVM  0.889658   0.887640  0.221910  0.355056   0.740244\n",
       "2        Random Forest  0.917724   0.986301  0.404494  0.573705   0.914108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.889273356401384\n",
      "Precision: 0.9594594594594594\n",
      "Recall: 0.199438202247191\n",
      "F1 Score: 0.3302325581395349\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.8877354863514033\n",
      "Precision: 0.9848484848484849\n",
      "Recall: 0.18258426966292135\n",
      "F1 Score: 0.3080568720379147\n",
      "AUC Score: 0.8834319711718926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to compute the required metrics and store the results\n",
    "# def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "#     # Compute label distribution (normalized)\n",
    "#     label_counts = train_data['label'].value_counts(normalize=True)\n",
    "#     # Length of the dataset\n",
    "#     length = len(train_data)\n",
    "#     # Compute AUC score\n",
    "#     AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "#     # Create a dictionary of results\n",
    "#     result = {\n",
    "#         'dataset': dataset_name,\n",
    "#         'class_0_proportion': label_counts.get(0, 0),\n",
    "#         'class_1_proportion': label_counts.get(1, 0),\n",
    "#         'dataset_size': length,\n",
    "#         'AUC': AUC_ensemble\n",
    "#     }\n",
    "\n",
    "#     # Convert the result dictionary to a DataFrame (single row)\n",
    "#     result_df = pd.DataFrame([result])\n",
    "\n",
    "#     # Check if the output file exists, if not create it with headers\n",
    "#     try:\n",
    "#         # Try to append to the file\n",
    "#         result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "#     except FileNotFoundError:\n",
    "#         # If the file doesn't exist, create it with headers\n",
    "#         result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# # Example usage for a single dataset:\n",
    "# # Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# # Example:\n",
    "# # Assuming you have the following variables\n",
    "# # train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# # y_test = your_test_labels\n",
    "# # y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# # Store metrics for the current dataset\n",
    "# store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='CassDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
