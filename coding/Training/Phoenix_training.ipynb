{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-maryannxue@apache.org</th>\n",
       "      <th>F71-jzhong@JZhongs-MacBook-Pro.local</th>\n",
       "      <th>F71-elilevine@apache.org</th>\n",
       "      <th>F71-stoens@apache.org</th>\n",
       "      <th>F71-gabrielr@ngdata.com</th>\n",
       "      <th>F71-rajeshbabu@apache.org</th>\n",
       "      <th>F71-ramkrishna.s.vasudevan@gmail.com</th>\n",
       "      <th>F71-mujtaba@apache.org</th>\n",
       "      <th>F71-wei.xue@intel.com</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.745370</td>\n",
       "      <td>0.810767</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.065327</td>\n",
       "      <td>0.206702</td>\n",
       "      <td>0.344086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.678630</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.141916</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.678630</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.028801</td>\n",
       "      <td>0.141916</td>\n",
       "      <td>0.631387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.678630</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>0.141916</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.678630</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>0.141916</td>\n",
       "      <td>0.631387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.928222</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.059509</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.662105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.928222</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.067118</td>\n",
       "      <td>0.137772</td>\n",
       "      <td>0.662105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.928222</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.074212</td>\n",
       "      <td>0.137772</td>\n",
       "      <td>0.493157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.928222</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.095495</td>\n",
       "      <td>0.137772</td>\n",
       "      <td>0.493157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.928222</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.084144</td>\n",
       "      <td>0.137772</td>\n",
       "      <td>0.493157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25    F65       F68      F101      F104      F105  \\\n",
       "0     0.745370  0.810767  0.015  0.010870  0.065327  0.206702  0.344086   \n",
       "1     0.637037  0.678630  0.050  0.070652  0.029263  0.141916  0.815694   \n",
       "2     0.637037  0.678630  0.050  0.070652  0.028801  0.141916  0.631387   \n",
       "3     0.637037  0.678630  0.050  0.070652  0.021643  0.141916  0.815694   \n",
       "4     0.637037  0.678630  0.050  0.070652  0.021181  0.141916  0.631387   \n",
       "...        ...       ...    ...       ...       ...       ...       ...   \n",
       "2230  0.828704  0.928222  0.040  0.038043  0.059509  0.067668  0.662105   \n",
       "2231  0.828704  0.928222  0.030  0.038043  0.067118  0.137772  0.662105   \n",
       "2232  0.828704  0.928222  0.030  0.038043  0.074212  0.137772  0.493157   \n",
       "2233  0.828704  0.928222  0.030  0.038043  0.095495  0.137772  0.493157   \n",
       "2234  0.828704  0.928222  0.030  0.038043  0.084144  0.137772  0.493157   \n",
       "\n",
       "      F15-NA  F15-private  F15-protected  ...  F71-maryannxue@apache.org  \\\n",
       "0        0.0          0.0            0.0  ...                        0.0   \n",
       "1        0.0          0.0            0.0  ...                        0.0   \n",
       "2        0.0          0.0            0.0  ...                        0.0   \n",
       "3        0.0          0.0            0.0  ...                        0.0   \n",
       "4        0.0          0.0            0.0  ...                        0.0   \n",
       "...      ...          ...            ...  ...                        ...   \n",
       "2230     0.0          0.0            0.0  ...                        0.0   \n",
       "2231     0.0          0.0            0.0  ...                        0.0   \n",
       "2232     0.0          0.0            0.0  ...                        0.0   \n",
       "2233     0.0          0.0            0.0  ...                        0.0   \n",
       "2234     0.0          0.0            0.0  ...                        0.0   \n",
       "\n",
       "      F71-jzhong@JZhongs-MacBook-Pro.local  F71-elilevine@apache.org  \\\n",
       "0                                      0.0                       0.0   \n",
       "1                                      0.0                       0.0   \n",
       "2                                      0.0                       0.0   \n",
       "3                                      0.0                       0.0   \n",
       "4                                      0.0                       0.0   \n",
       "...                                    ...                       ...   \n",
       "2230                                   0.0                       0.0   \n",
       "2231                                   0.0                       0.0   \n",
       "2232                                   0.0                       0.0   \n",
       "2233                                   0.0                       0.0   \n",
       "2234                                   0.0                       0.0   \n",
       "\n",
       "      F71-stoens@apache.org  F71-gabrielr@ngdata.com  \\\n",
       "0                       0.0                      0.0   \n",
       "1                       0.0                      0.0   \n",
       "2                       0.0                      0.0   \n",
       "3                       0.0                      0.0   \n",
       "4                       0.0                      0.0   \n",
       "...                     ...                      ...   \n",
       "2230                    0.0                      0.0   \n",
       "2231                    0.0                      0.0   \n",
       "2232                    0.0                      0.0   \n",
       "2233                    0.0                      0.0   \n",
       "2234                    0.0                      0.0   \n",
       "\n",
       "      F71-rajeshbabu@apache.org  F71-ramkrishna.s.vasudevan@gmail.com  \\\n",
       "0                           0.0                                   0.0   \n",
       "1                           1.0                                   0.0   \n",
       "2                           1.0                                   0.0   \n",
       "3                           1.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "...                         ...                                   ...   \n",
       "2230                        0.0                                   0.0   \n",
       "2231                        0.0                                   0.0   \n",
       "2232                        0.0                                   0.0   \n",
       "2233                        0.0                                   0.0   \n",
       "2234                        0.0                                   0.0   \n",
       "\n",
       "      F71-mujtaba@apache.org  F71-wei.xue@intel.com  label  \n",
       "0                        0.0                    0.0      0  \n",
       "1                        0.0                    0.0      1  \n",
       "2                        0.0                    0.0      1  \n",
       "3                        0.0                    0.0      1  \n",
       "4                        0.0                    0.0      1  \n",
       "...                      ...                    ...    ...  \n",
       "2230                     0.0                    0.0      1  \n",
       "2231                     0.0                    0.0      0  \n",
       "2232                     0.0                    0.0      0  \n",
       "2233                     0.0                    0.0      0  \n",
       "2234                     0.0                    0.0      0  \n",
       "\n",
       "[2235 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/phoenix_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/phoenix_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8501465048137296\n",
      "Precision: 0.4\n",
      "Recall: 0.08746355685131195\n",
      "F1 Score: 0.14354066985645933\n",
      "AUC Score: 0.7067576926036439\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.8752616157388029\n",
      "Precision: 0.7472527472527473\n",
      "Recall: 0.19825072886297376\n",
      "F1 Score: 0.31336405529953915\n",
      "AUC Score: 0.7216812154271008\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.8777731268313101\n",
      "Precision: 0.8311688311688312\n",
      "Recall: 0.18658892128279883\n",
      "F1 Score: 0.3047619047619048\n",
      "AUC Score: 0.8918432894733093\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.850147</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.087464</td>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.706758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.875262</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.313364</td>\n",
       "      <td>0.721681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.877773</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.186589</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.891843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.850147   0.400000  0.087464  0.143541   0.706758\n",
       "1                  SVM  0.875262   0.747253  0.198251  0.313364   0.721681\n",
       "2        Random Forest  0.877773   0.831169  0.186589  0.304762   0.891843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('eva_phoenix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8698200083717036\n",
      "Precision: 0.7666666666666667\n",
      "Recall: 0.13411078717201166\n",
      "F1 Score: 0.228287841191067\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.8748430305567183\n",
      "Precision: 0.8235294117647058\n",
      "Recall: 0.16326530612244897\n",
      "F1 Score: 0.2725060827250608\n",
      "AUC Score: 0.8835970919578555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='PhoenixDataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
