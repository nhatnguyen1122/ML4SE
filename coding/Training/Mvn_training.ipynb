{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-NA</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-olamy@apache.org</th>\n",
       "      <th>F71-jvanzyl@apache.org</th>\n",
       "      <th>F71-brianf@apache.org</th>\n",
       "      <th>F71-ifedorenko@apache.org</th>\n",
       "      <th>F71-igor@ifedorenko.com</th>\n",
       "      <th>F71-bentmann@apache.org</th>\n",
       "      <th>F71-krosenvold@apache.org</th>\n",
       "      <th>F71-jason@tesla.io</th>\n",
       "      <th>F71-jdcasey@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231010</td>\n",
       "      <td>0.497231</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.538745</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.056993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231010</td>\n",
       "      <td>0.497231</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.561410</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.231010</td>\n",
       "      <td>0.497231</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.533656</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.189604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.516612</td>\n",
       "      <td>0.119854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.501763</td>\n",
       "      <td>0.119854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.533644</td>\n",
       "      <td>0.189613</td>\n",
       "      <td>0.626113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.563779</td>\n",
       "      <td>0.189613</td>\n",
       "      <td>0.615056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.674805</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.593304</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.930952</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          F72       F25       F65       F68      F101      F104      F105  \\\n",
       "0    0.231010  0.497231  0.089385  0.341463  0.538745  0.003993  0.056993   \n",
       "1    0.231010  0.497231  0.089385  0.341463  0.561410  0.003993  0.484293   \n",
       "2    0.231010  0.497231  0.089385  0.341463  0.533656  0.003993  0.189604   \n",
       "3    0.999461  1.000000  0.016760  0.341463  0.516612  0.119854  1.000000   \n",
       "4    0.999461  1.000000  0.016760  0.341463  0.501763  0.119854  1.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "808  0.000000  0.000000  0.139665  0.012195  0.533644  0.189613  0.626113   \n",
       "809  0.000000  0.000000  0.139665  0.012195  0.563779  0.189613  0.615056   \n",
       "810  0.000000  0.000000  0.016760  0.012195  0.674805  0.153561  1.000000   \n",
       "811  0.000000  0.000000  0.016760  0.012195  0.593304  0.153561  1.000000   \n",
       "812  0.000000  0.000000  0.016760  0.012195  0.930952  0.153561  1.000000   \n",
       "\n",
       "     F15-NA  F15-private  F15-protected  ...  F71-olamy@apache.org  \\\n",
       "0       0.0          0.0            0.0  ...                   1.0   \n",
       "1       0.0          0.0            0.0  ...                   1.0   \n",
       "2       0.0          0.0            0.0  ...                   1.0   \n",
       "3       0.0          0.0            0.0  ...                   0.0   \n",
       "4       0.0          0.0            0.0  ...                   0.0   \n",
       "..      ...          ...            ...  ...                   ...   \n",
       "808     0.0          0.0            0.0  ...                   0.0   \n",
       "809     0.0          0.0            0.0  ...                   0.0   \n",
       "810     0.0          0.0            0.0  ...                   0.0   \n",
       "811     0.0          0.0            0.0  ...                   0.0   \n",
       "812     0.0          0.0            0.0  ...                   0.0   \n",
       "\n",
       "     F71-jvanzyl@apache.org  F71-brianf@apache.org  F71-ifedorenko@apache.org  \\\n",
       "0                       1.0                    0.0                        1.0   \n",
       "1                       1.0                    0.0                        1.0   \n",
       "2                       0.0                    0.0                        0.0   \n",
       "3                       1.0                    0.0                        0.0   \n",
       "4                       1.0                    0.0                        0.0   \n",
       "..                      ...                    ...                        ...   \n",
       "808                     0.0                    0.0                        0.0   \n",
       "809                     0.0                    0.0                        0.0   \n",
       "810                     0.0                    0.0                        0.0   \n",
       "811                     0.0                    0.0                        0.0   \n",
       "812                     0.0                    0.0                        0.0   \n",
       "\n",
       "     F71-igor@ifedorenko.com  F71-bentmann@apache.org  \\\n",
       "0                        0.0                      1.0   \n",
       "1                        0.0                      1.0   \n",
       "2                        0.0                      1.0   \n",
       "3                        0.0                      1.0   \n",
       "4                        0.0                      1.0   \n",
       "..                       ...                      ...   \n",
       "808                      0.0                      0.0   \n",
       "809                      0.0                      0.0   \n",
       "810                      0.0                      0.0   \n",
       "811                      0.0                      0.0   \n",
       "812                      0.0                      0.0   \n",
       "\n",
       "     F71-krosenvold@apache.org  F71-jason@tesla.io  F71-jdcasey@apache.org  \\\n",
       "0                          1.0                 1.0                     1.0   \n",
       "1                          1.0                 1.0                     0.0   \n",
       "2                          0.0                 1.0                     0.0   \n",
       "3                          0.0                 0.0                     0.0   \n",
       "4                          0.0                 0.0                     0.0   \n",
       "..                         ...                 ...                     ...   \n",
       "808                        0.0                 0.0                     0.0   \n",
       "809                        0.0                 0.0                     0.0   \n",
       "810                        0.0                 0.0                     0.0   \n",
       "811                        0.0                 0.0                     0.0   \n",
       "812                        0.0                 0.0                     0.0   \n",
       "\n",
       "     label  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "808      0  \n",
       "809      0  \n",
       "810      0  \n",
       "811      0  \n",
       "812      0  \n",
       "\n",
       "[813 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/mvn_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/mvn_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F72', 'F25', 'F65', 'F68', 'F101', 'F104', 'F105', 'F15-NA',\n",
    "       'F15-private', 'F15-protected', 'F15-public', 'F22', 'F123', 'F77',\n",
    "       'F41', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9547677261613692\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC Score: 0.8513110307414105\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.960880195599022\n",
      "Precision: 0.25\n",
      "Recall: 0.07142857142857142\n",
      "F1 Score: 0.1111111111111111\n",
      "AUC Score: 0.5967902350813743\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9645476772616137\n",
      "Precision: 0.4444444444444444\n",
      "Recall: 0.14285714285714285\n",
      "F1 Score: 0.21621621621621623\n",
      "AUC Score: 0.9677667269439422\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.954768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.960880</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.596790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.964548</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.967767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.954768   0.000000  0.000000  0.000000   0.851311\n",
       "1                  SVM  0.960880   0.250000  0.071429  0.111111   0.596790\n",
       "2        Random Forest  0.964548   0.444444  0.142857  0.216216   0.967767"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('eva_mvn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.9682151589242054\n",
      "Precision: 1.0\n",
      "Recall: 0.07142857142857142\n",
      "F1 Score: 0.13333333333333333\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.9682151589242054\n",
      "Precision: 1.0\n",
      "Recall: 0.07142857142857142\n",
      "F1 Score: 0.13333333333333333\n",
      "AUC Score: 0.9026672694394213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the required metrics and store the results\n",
    "def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "    # Compute label distribution (normalized)\n",
    "    label_counts = train_data['label'].value_counts(normalize=True)\n",
    "    # Length of the dataset\n",
    "    length = len(train_data)\n",
    "    # Compute AUC score\n",
    "    AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "    # Create a dictionary of results\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'class_0_proportion': label_counts.get(0, 0),\n",
    "        'class_1_proportion': label_counts.get(1, 0),\n",
    "        'dataset_size': length,\n",
    "        'AUC': AUC_ensemble\n",
    "    }\n",
    "\n",
    "    # Convert the result dictionary to a DataFrame (single row)\n",
    "    result_df = pd.DataFrame([result])\n",
    "\n",
    "    # Check if the output file exists, if not create it with headers\n",
    "    try:\n",
    "        # Try to append to the file\n",
    "        result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create it with headers\n",
    "        result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# Example usage for a single dataset:\n",
    "# Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# Example:\n",
    "# Assuming you have the following variables\n",
    "# train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# y_test = your_test_labels\n",
    "# y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# Store metrics for the current dataset\n",
    "store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='MvnDataset')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
