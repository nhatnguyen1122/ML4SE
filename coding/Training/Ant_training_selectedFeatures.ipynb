{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F72</th>\n",
       "      <th>F25</th>\n",
       "      <th>F65</th>\n",
       "      <th>F68</th>\n",
       "      <th>F101</th>\n",
       "      <th>F104</th>\n",
       "      <th>F105</th>\n",
       "      <th>F15-private</th>\n",
       "      <th>F15-protected</th>\n",
       "      <th>F15-public</th>\n",
       "      <th>...</th>\n",
       "      <th>F71-sbailliez@apache.org</th>\n",
       "      <th>F71-ehatcher@apache.org</th>\n",
       "      <th>F71-costin@apache.org</th>\n",
       "      <th>F71-rubys@apache.org</th>\n",
       "      <th>F71-peterreilly@apache.org</th>\n",
       "      <th>F71-hibou@apache.org</th>\n",
       "      <th>F71-conor@apache.org</th>\n",
       "      <th>F71-mbenson@apache.org</th>\n",
       "      <th>F71-jhm@apache.org</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794814</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.060358</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794814</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.170772</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>0.829676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794814</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.081054</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>0.622853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794814</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.017716</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>0.710719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.794814</td>\n",
       "      <td>0.856370</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.129722</td>\n",
       "      <td>0.233491</td>\n",
       "      <td>0.210314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>0.900085</td>\n",
       "      <td>0.906651</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.120907</td>\n",
       "      <td>0.134318</td>\n",
       "      <td>0.190212</td>\n",
       "      <td>0.907096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.261418</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.120907</td>\n",
       "      <td>0.134318</td>\n",
       "      <td>0.188549</td>\n",
       "      <td>0.872257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>0.637839</td>\n",
       "      <td>0.834936</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0.350547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.838056</td>\n",
       "      <td>0.866587</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.096023</td>\n",
       "      <td>0.212986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1229 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           F72       F25    F65       F68      F101      F104      F105  \\\n",
       "0     0.794814  0.856370  0.480  0.372796  0.060358  0.233491  1.000000   \n",
       "1     0.794814  0.856370  0.480  0.372796  0.170772  0.233491  0.829676   \n",
       "2     0.794814  0.856370  0.480  0.372796  0.081054  0.233491  0.622853   \n",
       "3     0.794814  0.856370  0.480  0.372796  0.017716  0.233491  0.710719   \n",
       "4     0.794814  0.856370  0.480  0.372796  0.129722  0.233491  0.210314   \n",
       "...        ...       ...    ...       ...       ...       ...       ...   \n",
       "1224  0.900085  0.906651  0.048  0.120907  0.134318  0.190212  0.907096   \n",
       "1225  0.062961  0.261418  0.096  0.120907  0.134318  0.188549  0.872257   \n",
       "1226  0.000000  0.000000  0.008  0.040302  0.138179  0.746555  1.000000   \n",
       "1227  0.637839  0.834936  0.016  0.040302  0.138026  0.350547  1.000000   \n",
       "1228  0.838056  0.866587  0.024  0.002519  0.096023  0.212986  1.000000   \n",
       "\n",
       "      F15-private  F15-protected  F15-public  ...  F71-sbailliez@apache.org  \\\n",
       "0             0.0            0.0         0.0  ...                       0.0   \n",
       "1             0.0            0.0         0.0  ...                       0.0   \n",
       "2             0.0            0.0         0.0  ...                       1.0   \n",
       "3             0.0            0.0         1.0  ...                       1.0   \n",
       "4             0.0            0.0         0.0  ...                       1.0   \n",
       "...           ...            ...         ...  ...                       ...   \n",
       "1224          0.0            0.0         0.0  ...                       0.0   \n",
       "1225          0.0            0.0         0.0  ...                       0.0   \n",
       "1226          0.0            0.0         1.0  ...                       0.0   \n",
       "1227          0.0            0.0         1.0  ...                       0.0   \n",
       "1228          0.0            0.0         1.0  ...                       0.0   \n",
       "\n",
       "      F71-ehatcher@apache.org  F71-costin@apache.org  F71-rubys@apache.org  \\\n",
       "0                         1.0                    1.0                   0.0   \n",
       "1                         0.0                    0.0                   0.0   \n",
       "2                         1.0                    1.0                   1.0   \n",
       "3                         1.0                    1.0                   1.0   \n",
       "4                         1.0                    1.0                   1.0   \n",
       "...                       ...                    ...                   ...   \n",
       "1224                      0.0                    0.0                   0.0   \n",
       "1225                      0.0                    0.0                   0.0   \n",
       "1226                      0.0                    0.0                   0.0   \n",
       "1227                      0.0                    0.0                   0.0   \n",
       "1228                      0.0                    0.0                   0.0   \n",
       "\n",
       "      F71-peterreilly@apache.org  F71-hibou@apache.org  F71-conor@apache.org  \\\n",
       "0                            1.0                   0.0                   1.0   \n",
       "1                            0.0                   0.0                   0.0   \n",
       "2                            1.0                   0.0                   1.0   \n",
       "3                            1.0                   0.0                   1.0   \n",
       "4                            1.0                   0.0                   1.0   \n",
       "...                          ...                   ...                   ...   \n",
       "1224                         1.0                   0.0                   0.0   \n",
       "1225                         0.0                   0.0                   0.0   \n",
       "1226                         0.0                   0.0                   0.0   \n",
       "1227                         1.0                   0.0                   0.0   \n",
       "1228                         0.0                   0.0                   0.0   \n",
       "\n",
       "      F71-mbenson@apache.org  F71-jhm@apache.org  label  \n",
       "0                        1.0                 0.0      1  \n",
       "1                        1.0                 0.0      0  \n",
       "2                        1.0                 0.0      0  \n",
       "3                        1.0                 0.0      0  \n",
       "4                        1.0                 0.0      0  \n",
       "...                      ...                 ...    ...  \n",
       "1224                     1.0                 0.0      0  \n",
       "1225                     0.0                 0.0      0  \n",
       "1226                     0.0                 0.0      0  \n",
       "1227                     1.0                 0.0      0  \n",
       "1228                     1.0                 0.0      0  \n",
       "\n",
       "[1229 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"../dataset/ant_train.csv\")\n",
    "test_data = pd.read_csv(\"../dataset/ant_test.csv\")\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['F123', 'F105', 'F25', 'F72', 'F77', 'F68', 'F41', 'F65', 'F126']\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression:  {'C': 10, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_logistic = GridSearchCV(logistic_model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters for Logistic Regression: \", grid_search_logistic.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.895067264573991\n",
      "Precision: 0.043478260869565216\n",
      "Recall: 0.05555555555555555\n",
      "F1 Score: 0.04878048780487805\n",
      "AUC Score: 0.5743184277585786\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_logistic = grid_search_logistic.predict(X_test)\n",
    "y_proba_logistic = grid_search_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation Metrics for Logistic Regression\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_logistic))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_logistic))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_logistic))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm_model, param_grid_svm, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.7982062780269058\n",
      "Precision: 0.09090909090909091\n",
      "Recall: 0.35185185185185186\n",
      "F1 Score: 0.1444866920152091\n",
      "AUC Score: 0.5687855621880127\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "y_proba_svm = grid_search_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='f1')\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.809865470852018\n",
      "Precision: 0.07526881720430108\n",
      "Recall: 0.25925925925925924\n",
      "F1 Score: 0.11666666666666667\n",
      "AUC Score: 0.7122211749921457\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = grid_search_rf.predict(X_test)\n",
    "y_proba_rf = grid_search_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.895067</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.574318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.144487</td>\n",
       "      <td>0.568786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.809865</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.712221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score  AUC Score\n",
       "0  Logistic Regression  0.895067   0.043478  0.055556  0.048780   0.574318\n",
       "1                  SVM  0.798206   0.090909  0.351852  0.144487   0.568786\n",
       "2        Random Forest  0.809865   0.075269  0.259259  0.116667   0.712221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the models\n",
    "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_logistic),\n",
    "    accuracy_score(y_test, y_pred_svm),\n",
    "    accuracy_score(y_test, y_pred_rf)\n",
    "]\n",
    "precisions = [\n",
    "    precision_score(y_test, y_pred_logistic),\n",
    "    precision_score(y_test, y_pred_svm),\n",
    "    precision_score(y_test, y_pred_rf)\n",
    "]\n",
    "recalls = [\n",
    "    recall_score(y_test, y_pred_logistic),\n",
    "    recall_score(y_test, y_pred_svm),\n",
    "    recall_score(y_test, y_pred_rf)\n",
    "]\n",
    "f1_scores = [\n",
    "    f1_score(y_test, y_pred_logistic),\n",
    "    f1_score(y_test, y_pred_svm),\n",
    "    f1_score(y_test, y_pred_rf)\n",
    "]\n",
    "auc_scores = [\n",
    "    roc_auc_score(y_test, y_proba_logistic),\n",
    "    roc_auc_score(y_test, y_proba_svm),\n",
    "    roc_auc_score(y_test, y_proba_rf)\n",
    "]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the F1 Score comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, f1_scores, color=['blue', 'green', 'red'])\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier Metrics:\n",
      "Accuracy: 0.8340807174887892\n",
      "Precision: 0.0718954248366013\n",
      "Recall: 0.2037037037037037\n",
      "F1 Score: 0.10628019323671498\n",
      "AUC Score: Not available for hard voting\n",
      "\n",
      "Soft Voting Classifier Metrics:\n",
      "Accuracy: 0.8780269058295964\n",
      "Precision: 0.07291666666666667\n",
      "Recall: 0.12962962962962962\n",
      "F1 Score: 0.09333333333333334\n",
      "AUC Score: 0.6561594582329737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('logistic', grid_search_logistic.best_estimator_),\n",
    "    ('svm', grid_search_svm.best_estimator_),\n",
    "    ('rf', grid_search_rf.best_estimator_)\n",
    "]\n",
    "\n",
    "# Hard Voting Classifier (majority voting)\n",
    "hard_voting_clf = VotingClassifier(estimators=base_models, voting='hard')\n",
    "hard_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using hard voting (class predictions)\n",
    "y_pred_hard_voting = hard_voting_clf.predict(X_test)\n",
    "\n",
    "# Metrics for Hard Voting \n",
    "print(\"Hard Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_hard_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_hard_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_hard_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_hard_voting))\n",
    "print(\"AUC Score: Not available for hard voting\\n\")\n",
    "\n",
    "# Soft Voting Classifier (average probabilities)\n",
    "soft_voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "soft_voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate soft voting (probabilities are available)\n",
    "y_pred_soft_voting = soft_voting_clf.predict(X_test)\n",
    "y_proba_soft_voting = soft_voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Soft Voting Classifier Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_soft_voting))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_soft_voting))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_soft_voting))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_soft_voting))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba_soft_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to compute the required metrics and store the results\n",
    "# def store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name, output_file='dataset_comparison.csv'):\n",
    "#     # Compute label distribution (normalized)\n",
    "#     label_counts = train_data['label'].value_counts(normalize=True)\n",
    "#     # Length of the dataset\n",
    "#     length = len(train_data)\n",
    "#     # Compute AUC score\n",
    "#     AUC_ensemble = roc_auc_score(y_test, y_proba_soft_voting)\n",
    "    \n",
    "#     # Create a dictionary of results\n",
    "#     result = {\n",
    "#         'dataset': dataset_name,\n",
    "#         'class_0_proportion': label_counts.get(0, 0),\n",
    "#         'class_1_proportion': label_counts.get(1, 0),\n",
    "#         'dataset_size': length,\n",
    "#         'AUC': AUC_ensemble\n",
    "#     }\n",
    "\n",
    "#     # Convert the result dictionary to a DataFrame (single row)\n",
    "#     result_df = pd.DataFrame([result])\n",
    "\n",
    "#     # Check if the output file exists, if not create it with headers\n",
    "#     try:\n",
    "#         # Try to append to the file\n",
    "#         result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "#     except FileNotFoundError:\n",
    "#         # If the file doesn't exist, create it with headers\n",
    "#         result_df.to_csv(output_file, mode='w', header=True, index=False)\n",
    "\n",
    "# # Example usage for a single dataset:\n",
    "# # Replace 'train_data', 'y_test', 'y_proba_soft_voting' with actual data\n",
    "\n",
    "# # Example:\n",
    "# # Assuming you have the following variables\n",
    "# # train_data = pd.read_csv('some_dataset.csv') # Load your train dataset\n",
    "# # y_test = your_test_labels\n",
    "# # y_proba_soft_voting = your_model_predictions_probabilities\n",
    "\n",
    "# # Store metrics for the current dataset\n",
    "# store_metrics(train_data, y_test, y_proba_soft_voting, dataset_name='AntDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
